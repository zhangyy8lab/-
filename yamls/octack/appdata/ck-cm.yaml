kind: ConfigMap
apiVersion: v1
metadata:
  name: ck-cm
  namespace: appdata
data:
  config.xml: |
    <?xml version="1.0"?>
    <clickhouse>
        <macros>
            <shard from_env="SHARD" />
            <replica from_env="HOSTNAME" />
        </macros>
        <logger>
            <level>information</level>
            <console>1</console>
        </logger>
        <http_port>8123</http_port>
        <tcp_port>9000</tcp_port>
        <path>/usr/local/clickhouse/</path>
        <include_from>/etc/clickhouse-server/metrica.xml</include_from>
        <zookeeper incl="zookeeper" />
        <!-- https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings#database_atomic_delay_before_drop_table_sec  -->
        <database_atomic_delay_before_drop_table_sec>0</database_atomic_delay_before_drop_table_sec>
        <database_catalog_unused_dir_hide_timeout_sec>0</database_catalog_unused_dir_hide_timeout_sec>
        <remote_servers incl="remote_servers" />
        <default_replica_path>/clickhouse/tables/{shard}/{database}/{table}</default_replica_path>
        <default_replica_name>{replica}</default_replica_name>
        <interserver_http_port>9009</interserver_http_port>
        <interserver_http_credentials>
            <user>octa8lab</user>
            <password>octa8lab</password>
        </interserver_http_credentials>
        <listen_host>0.0.0.0</listen_host>
        <listen_backlog>4096</listen_backlog>
        <max_connections>4096</max_connections>
        <keep_alive_timeout>5</keep_alive_timeout>
        <max_concurrent_queries>100</max_concurrent_queries>
        <max_server_memory_usage>0</max_server_memory_usage>
        <max_thread_pool_size>10000</max_thread_pool_size>
        <max_server_memory_usage_to_ram_ratio>0.9</max_server_memory_usage_to_ram_ratio>
        <total_memory_profiler_step>4194304</total_memory_profiler_step>
        <total_memory_tracker_sample_probability>0</total_memory_tracker_sample_probability>
        <uncompressed_cache_size>8589934592</uncompressed_cache_size>
        <mark_cache_size>5368709120</mark_cache_size>
        <mmap_cache_size>1000</mmap_cache_size>
        <compiled_expression_cache_size>134217728</compiled_expression_cache_size>
        <compiled_expression_cache_elements_size>10000</compiled_expression_cache_elements_size>
    
        <!-- Path to temporary data for processing hard queries. -->
        <tmp_path>/usr/local/clickhouse/tmp/</tmp_path>
    
        <!-- Disable AuthType plaintext_password and no_password for ACL. -->
        <!-- <allow_plaintext_password>0</allow_plaintext_password> -->
        <!-- <allow_no_password>0</allow_no_password> -->`
    
        <!-- Directory with user provided files that are accessible by 'file' table function. -->
        <user_files_path>/usr/local/clickhouse/user_files/</user_files_path>
    
        <!-- Sources to read users, roles, access rights, profiles of settings, quotas. -->
        <user_directories>
            <users_xml>
                <path>/etc/clickhouse-server/users.xml</path>
            </users_xml>
            <local_directory>
                <!-- Path to folder where users created by SQL commands are stored. -->
                <path>/usr/local/clickhouse/access/</path>
            </local_directory>
        </user_directories>
        <storage_configuration>
            <disks>
                <backups>
                    <type>local</type>
                    <path>/tmp/</path>
                </backups>
            </disks>
        </storage_configuration>
        <backups>
            <allowed_disk>backups</allowed_disk>
        </backups>
    
        <!-- Default profile of settings. -->
        <default_profile>default</default_profile>
    
        <!-- Comma-separated list of prefixes for user-defined settings. -->
        <custom_settings_prefixes></custom_settings_prefixes>
    
        <distributed_ddl>
          <!-- Path in ZooKeeper to queue with DDL queries -->
          <path>/clickhouse/task_queue/ddl</path>
          <pool_size>20</pool_size>
          <cleanup_delay_period>60</cleanup_delay_period>
          <task_max_lifetime>86400</task_max_lifetime>
          <max_tasks_in_queue>1000</max_tasks_in_queue>
        </distributed_ddl>
    
        <!-- Buffer profile of settings.
             This settings are used by Buffer storage to flush data to the underlying table.
             Default: used from system_profile directive.
        -->
        <!-- <buffer_profile>default</buffer_profile> -->
    
        <!-- Default database. -->
        <default_database>default</default_database>
    
        <!-- <timezone>UTC</timezone> -->
    
        <!-- Perform mlockall after startup to lower first queries latency
              and to prevent clickhouse executable from being paged out under high IO load.
             Enabling this option is recommended but will lead to increased startup time for up to a few seconds.
        -->
        <mlock_executable>true</mlock_executable>
    
        <!-- Reallocate memory for machine code ("text") using huge pages. Highly experimental. -->
        <remap_executable>false</remap_executable>
    
        <!-- Reloading interval for embedded dictionaries, in seconds. Default: 3600. -->
        <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>
    
    
        <!-- Maximum session timeout, in seconds. Default: 3600. -->
        <max_session_timeout>3600</max_session_timeout>
    
        <!-- Default session timeout, in seconds. Default: 60. -->
        <default_session_timeout>60</default_session_timeout>
    
        <!-- Serve endpoint for Prometheus monitoring. -->
        <!--
            endpoint - mertics path (relative to root, statring with "/")
            port - port to setup server. If not defined or 0 than http_port used
            metrics - send data from table system.metrics
            events - send data from table system.events
            asynchronous_metrics - send data from table system.asynchronous_metrics
            status_info - send data from different component from CH, ex: Dictionaries status
        -->
        <!--
        <prometheus>
            <endpoint>/metrics</endpoint>
            <port>9363</port>
    
            <metrics>true</metrics>
            <events>true</events>
            <asynchronous_metrics>true</asynchronous_metrics>
            <status_info>true</status_info>
        </prometheus>
        -->
    
        <!-- Query log. Used only for queries with setting log_queries = 1. -->
        <query_log>
            <!-- What table to insert data. If table is not exist, it will be created.
                 When query log structure is changed after system update,
                  then old table will be renamed and new table will be created automatically.
            -->
            <database>system</database>
            <table>query_log</table>
            <!--
                PARTITION BY expr: https://clickhouse.com/docs/en/table_engines/mergetree-family/custom_partitioning_key/
                Example:
                    event_date
                    toMonday(event_date)
                    toYYYYMM(event_date)
                    toStartOfHour(event_time)
            -->
            <partition_by>toYYYYMM(event_date)</partition_by>
            <!--
                Table TTL specification: https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/mergetree/#mergetree-table-ttl
                Example:
                    event_date + INTERVAL 1 WEEK
                    event_date + INTERVAL 7 DAY DELETE
                    event_date + INTERVAL 2 WEEK TO DISK 'bbb'
    
            <ttl>event_date + INTERVAL 30 DAY DELETE</ttl>
            -->
    
            <!-- Instead of partition_by, you can provide full engine expression (starting with ENGINE = ) with parameters,
                 Example: <engine>ENGINE = MergeTree PARTITION BY toYYYYMM(event_date) ORDER BY (event_date, event_time) SETTINGS index_granularity = 1024</engine>
              -->
    
            <!-- Interval of flushing data. -->
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </query_log>
    
        <!-- Trace log. Stores stack traces collected by query profilers.
             See query_profiler_real_time_period_ns and query_profiler_cpu_time_period_ns settings. -->
        <trace_log>
            <database>system</database>
            <table>trace_log</table>
    
            <partition_by>toYYYYMM(event_date)</partition_by>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </trace_log>
    
        <!-- Query thread log. Has information about all threads participated in query execution.
             Used only for queries with setting log_query_threads = 1. -->
        <query_thread_log>
            <database>system</database>
            <table>query_thread_log</table>
            <partition_by>toYYYYMM(event_date)</partition_by>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </query_thread_log>
    
        <!-- Query views log. Has information about all dependent views associated with a query.
             Used only for queries with setting log_query_views = 1. -->
        <query_views_log>
            <database>system</database>
            <table>query_views_log</table>
            <partition_by>toYYYYMM(event_date)</partition_by>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </query_views_log>
    
        <!-- Uncomment if use part log.
             Part log contains information about all actions with parts in MergeTree tables (creation, deletion, merges, downloads).-->
        <part_log>
            <database>system</database>
            <table>part_log</table>
            <partition_by>toYYYYMM(event_date)</partition_by>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </part_log>
    
        <!-- Uncomment to write text log into table.
             Text log contains all information from usual server log but stores it in structured and efficient way.
             The level of the messages that goes to the table can be limited (<level>), if not specified all messages will go to the table.
        <text_log>
            <database>system</database>
            <table>text_log</table>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
            <level></level>
        </text_log>
        -->
    
        <!-- Metric log contains rows with current values of ProfileEvents, CurrentMetrics collected with "collect_interval_milliseconds" interval. -->
        <metric_log>
            <database>system</database>
            <table>metric_log</table>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
            <collect_interval_milliseconds>1000</collect_interval_milliseconds>
        </metric_log>
    
        <!--
            Asynchronous metric log contains values of metrics from
            system.asynchronous_metrics.
        -->
        <asynchronous_metric_log>
            <database>system</database>
            <table>asynchronous_metric_log</table>
            <!--
                Asynchronous metrics are updated once a minute, so there is
                no need to flush more often.
            -->
            <flush_interval_milliseconds>7000</flush_interval_milliseconds>
        </asynchronous_metric_log>
    
        <!--
            OpenTelemetry log contains OpenTelemetry trace spans.
        -->
        <opentelemetry_span_log>
            <!--
                The default table creation code is insufficient, this <engine> spec
                is a workaround. There is no 'event_time' for this log, but two times,
                start and finish. It is sorted by finish time, to avoid inserting
                data too far away in the past (probably we can sometimes insert a span
                that is seconds earlier than the last span in the table, due to a race
                between several spans inserted in parallel). This gives the spans a
                global order that we can use to e.g. retry insertion into some external
                system.
            -->
            <engine>
                engine MergeTree
                partition by toYYYYMM(finish_date)
                order by (finish_date, finish_time_us, trace_id)
            </engine>
            <database>system</database>
            <table>opentelemetry_span_log</table>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </opentelemetry_span_log>
    
    
        <!-- Crash log. Stores stack traces for fatal errors.
             This table is normally empty. -->
        <crash_log>
            <database>system</database>
            <table>crash_log</table>
    
            <partition_by />
            <flush_interval_milliseconds>1000</flush_interval_milliseconds>
        </crash_log>
    
        <dictionaries_config>*_dictionary.xml</dictionaries_config>
        <user_defined_executable_functions_config>*_function.xml</user_defined_executable_functions_config>
    
        <!-- Uncomment if you want data to be compressed 30-100% better.
             Don't do that if you just started using ClickHouse.
          -->
        <!--
        <compression>
            <!- - Set of variants. Checked in order. Last matching case wins. If nothing matches, lz4 will be used. - ->
            <case>
    
                <!- - Conditions. All must be satisfied. Some conditions may be omitted. - ->
                <min_part_size>10000000000</min_part_size>        <!- - Min part size in bytes. - ->
                <min_part_size_ratio>0.01</min_part_size_ratio>   <!- - Min size of part relative to whole table size. - ->
    
                <!- - What compression method to use. - ->
                <method>zstd</method>
            </case>
        </compression>
        -->
    
        <merge_tree>
            <max_suspicious_broken_parts>5</max_suspicious_broken_parts>
        </merge_tree>
        <max_table_size_to_drop>0</max_table_size_to_drop>
        <max_partition_size_to_drop>0</max_partition_size_to_drop>
    
        <format_schema_path>/usr/local/clickhouse/format_schemas/</format_schema_path>
        <send_crash_reports>
            <enabled>true</enabled>
            <anonymize>true</anonymize>
            <endpoint>https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277</endpoint>
        </send_crash_reports>
        <disable_internal_dns_cache>1</disable_internal_dns_cache>
        <!-- Uncomment if enable merge tree metadata cache -->
        <!--merge_tree_metadata_cache>
            <lru_cache_size>268435456</lru_cache_size>
            <continue_if_corrupted>true</continue_if_corrupted>
        </merge_tree_metadata_cache-->
    </clickhouse>
  metrica.xml: |
    <clickhouse>
      <remote_servers>
           <octa_ck_cluster>
               <shard>
                   <weight>1</weight>
                   <internal_replication>true</internal_replication>
                   <replica>
                       <host>ck-sts-0.ck-svc.appdata.svc.cluster.local</host>
                       <port>9000</port>
                       <user>octa8lab</user>
                       <password>octa8lab</password>
                   </replica>
                   <replica>
                       <host>ck-sts-1.ck-svc.appdata.svc.cluster.local</host>
                       <port>9000</port>
                       <user>octa8lab</user>
                       <password>octa8lab</password>
                       <user>octa8lab</user>
                   </replica>
               </shard>
               <shard>
                   <weight>1</weight>
                   <internal_replication>true</internal_replication>
                   <replica>
                       <host>ck-sts-2.ck-svc.appdata.svc.cluster.local</host>
                       <port>9000</port>
                       <user>octa8lab</user>
                       <password>octa8lab</password>
                   </replica>
                   <replica>
                       <host>ck-sts-3.ck-svc.appdata.svc.cluster.local</host>
                       <port>9000</port>
                       <user>octa8lab</user>
                       <password>octa8lab</password>
                   </replica>
               </shard>
           </octa_ck_cluster>
      </remote_servers>
      <zookeeper>
          <node>
              <host>ck-keeper-sts-0.ck-keeper-svc.appdata.svc.cluster.local</host>
              <port>9181</port>
             #<host>zk-0.zk.pulsar.svc.cluster.local</host>
             #<port>2181</port>
          </node>
          <node>
              <host>ck-keeper-sts-1.ck-keeper-svc.appdata.svc.cluster.local</host>
              <port>9181</port>
             #<host>zk-1.zk.pulsar.svc.cluster.local</host>
             #<port>2181</port>
          </node>
          <node>
              <host>ck-keeper-sts-2.ck-keeper-svc.appdata.svc.cluster.local</host>
              <port>9181</port>
             #<host>zk-2.zk.pulsar.svc.cluster.local</host>
             #<port>2181</port>
          </node>
      </zookeeper>
    </clickhouse>
  users.xml: |
    <?xml version="1.0"?>
    <clickhouse>
        <profiles>
            <default>
                <load_balancing>random</load_balancing>
            </default>
    
            <readonly>
                <readonly>1</readonly>
            </readonly>
        </profiles>
        <users>
            <default>
                <password_sha256_hex>35a8c26a4081eccd9186f84612e46572b0fead2b604180302db74e5617bebc8d</password_sha256_hex>
                <networks>
                    <ip>::1</ip>
                    <ip>127.0.0.1</ip>
                </networks>
                <profile>default</profile>
                <quota>default</quota>
                <access_management>1</access_management>
            </default>
            <octa8lab>
                <password_sha256_hex>35a8c26a4081eccd9186f84612e46572b0fead2b604180302db74e5617bebc8d</password_sha256_hex>
                <networks>
                   <ip>192.168.0.0/16</ip>
                   <ip>10.0.0.0/8</ip>
                   <ip>::/0</ip>
                </networks>
                <profile>default</profile>
                <quota>default</quota>
                <access_management>0</access_management>
                <grants>
                    <query>GRANT SHOW, SELECT, INSERT, ALTER, CREATE, DROP, UNDROP TABLE, TRUNCATE, OPTIMIZE, BACKUP, KILL QUERY, KILL TRANSACTION, MOVE PARTITION BETWEEN SHARDS, ACCESS MANAGEMENT, SYSTEM, dictGet, displaySecretsInShowAndSelect, INTROSPECTION, SOURCES ON *.* WITH GRANT OPTION</query>
                </grants>
            </octa8lab>
        </users>
    
        <!-- Quotas. -->
        <quotas>
            <!-- Name of quota. -->
            <default>
                <!-- Limits for time interval. You could specify many intervals with different limits. -->
                <interval>
                    <!-- Length of interval. -->
                    <duration>3600</duration>
                    <!-- No limits. Just calculate resource usage for time interval. -->
                    <queries>0</queries>
                    <errors>0</errors>
                    <result_rows>0</result_rows>
                    <read_rows>0</read_rows>
                    <execution_time>0</execution_time>
                </interval>
            </default>
        </quotas>
    </clickhouse>
